Downloading and preparing dataset csv/default to /users/annieske/.cache/huggingface/datasets/csv/default-f8dd2bf89ca29012/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...
Dataset csv downloaded and prepared to /users/annieske/.cache/huggingface/datasets/csv/default-f8dd2bf89ca29012/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.
['IP', 'IN', 'IN', 'IN', None]
[['IP'], ['IN'], ['IN'], ['IN'], ['NA']]
[[0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0],
 [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0]]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 0.3091, 'learning_rate': 8.333333333333334e-06, 'epoch': 1.0}
{'eval_loss': 0.19931067526340485, 'eval_f1': 0.7386363636363636, 'eval_roc_auc': 0.8330583654793938, 'eval_accuracy': 0.6391437308868502, 'eval_runtime': 20.6735, 'eval_samples_per_second': 31.635, 'eval_steps_per_second': 1.016, 'epoch': 1.0}
{'loss': 0.1791, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}
{'eval_loss': 0.18224917352199554, 'eval_f1': 0.775654635527247, 'eval_roc_auc': 0.8544132714493623, 'eval_accuracy': 0.6957186544342507, 'eval_runtime': 20.4127, 'eval_samples_per_second': 32.039, 'eval_steps_per_second': 1.029, 'epoch': 2.0}
{'loss': 0.1301, 'learning_rate': 5e-06, 'epoch': 3.0}
{'eval_loss': 0.15047086775302887, 'eval_f1': 0.8231245698554716, 'eval_roc_auc': 0.8890846487167252, 'eval_accuracy': 0.7400611620795107, 'eval_runtime': 20.4428, 'eval_samples_per_second': 31.992, 'eval_steps_per_second': 1.027, 'epoch': 3.0}
{'loss': 0.1014, 'learning_rate': 3.3333333333333333e-06, 'epoch': 4.0}
{'eval_loss': 0.14821425080299377, 'eval_f1': 0.831275720164609, 'eval_roc_auc': 0.894788075319753, 'eval_accuracy': 0.7431192660550459, 'eval_runtime': 20.4481, 'eval_samples_per_second': 31.983, 'eval_steps_per_second': 1.027, 'epoch': 4.0}
{'loss': 0.0764, 'learning_rate': 1.6666666666666667e-06, 'epoch': 5.0}
{'eval_loss': 0.15424582362174988, 'eval_f1': 0.8267770876466528, 'eval_roc_auc': 0.8903129548000711, 'eval_accuracy': 0.7385321100917431, 'eval_runtime': 20.4092, 'eval_samples_per_second': 32.044, 'eval_steps_per_second': 1.029, 'epoch': 5.0}
{'loss': 0.0648, 'learning_rate': 0.0, 'epoch': 6.0}
{'eval_loss': 0.1566525101661682, 'eval_f1': 0.8297725706409372, 'eval_roc_auc': 0.8924378106476129, 'eval_accuracy': 0.7431192660550459, 'eval_runtime': 20.42, 'eval_samples_per_second': 32.027, 'eval_steps_per_second': 1.028, 'epoch': 6.0}
{'train_runtime': 1029.0637, 'train_samples_per_second': 6.373, 'train_steps_per_second': 0.915, 'train_loss': 0.1434657710373022, 'epoch': 6.0}
F1: 0.8173374613003097

TEST WITH OTHER SWEDISH CORPORA
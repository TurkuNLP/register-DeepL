Downloading and preparing dataset csv/default to /users/annieske/.cache/huggingface/datasets/csv/default-2984d10107144ac0/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...
Dataset csv downloaded and prepared to /users/annieske/.cache/huggingface/datasets/csv/default-2984d10107144ac0/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.
['IN NA', 'LY', 'IP', 'IP', None]
[['IN', 'NA'], ['LY'], ['IP'], ['IP'], ['NA']]
[[0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0],
 [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0]]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 0.4053, 'learning_rate': 2.4000000000000003e-06, 'epoch': 1.0}
{'eval_loss': 0.34450820088386536, 'eval_f1': 0.0730593607305936, 'eval_roc_auc': 0.5179265237545191, 'eval_accuracy': 0.040293040293040296, 'eval_runtime': 16.715, 'eval_samples_per_second': 32.665, 'eval_steps_per_second': 1.077, 'epoch': 1.0}
{'loss': 0.3383, 'learning_rate': 1.8e-06, 'epoch': 2.0}
{'eval_loss': 0.32878050208091736, 'eval_f1': 0.14727540500736377, 'eval_roc_auc': 0.5393273428241401, 'eval_accuracy': 0.08241758241758242, 'eval_runtime': 16.7845, 'eval_samples_per_second': 32.53, 'eval_steps_per_second': 1.072, 'epoch': 2.0}
{'loss': 0.3185, 'learning_rate': 1.2000000000000002e-06, 'epoch': 3.0}
{'eval_loss': 0.3018091320991516, 'eval_f1': 0.5042553191489363, 'eval_roc_auc': 0.679527759859588, 'eval_accuracy': 0.36446886446886445, 'eval_runtime': 16.7993, 'eval_samples_per_second': 32.501, 'eval_steps_per_second': 1.071, 'epoch': 3.0}
{'loss': 0.2871, 'learning_rate': 6.000000000000001e-07, 'epoch': 4.0}
{'eval_loss': 0.27423331141471863, 'eval_f1': 0.6196377502383222, 'eval_roc_auc': 0.747350024752104, 'eval_accuracy': 0.48534798534798534, 'eval_runtime': 16.7904, 'eval_samples_per_second': 32.519, 'eval_steps_per_second': 1.072, 'epoch': 4.0}
{'loss': 0.2631, 'learning_rate': 0.0, 'epoch': 5.0}
{'eval_loss': 0.2629286050796509, 'eval_f1': 0.6168051708217913, 'eval_roc_auc': 0.7512353550051755, 'eval_accuracy': 0.4908424908424908, 'eval_runtime': 16.795, 'eval_samples_per_second': 32.51, 'eval_steps_per_second': 1.072, 'epoch': 5.0}
{'train_runtime': 607.9932, 'train_samples_per_second': 7.475, 'train_steps_per_second': 1.069, 'train_loss': 0.3224529207669772, 'epoch': 5.0}
F1: 0.6013986013986014

rerun
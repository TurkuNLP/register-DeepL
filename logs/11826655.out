Downloading and preparing dataset json/default to /users/annieske/.cache/huggingface/datasets/json/default-6723c60de6262879/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...
Dataset json downloaded and prepared to /users/annieske/.cache/huggingface/datasets/json/default-6723c60de6262879/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 2.9872, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.36}
{'eval_loss': 2.6262118816375732, 'eval_f1': 0.2007168458781362, 'eval_precision': 0.2007168458781362, 'eval_recall': 0.2007168458781362, 'eval_runtime': 2.7307, 'eval_samples_per_second': 102.17, 'eval_steps_per_second': 3.296, 'epoch': 0.36}
{'loss': 2.6508, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.72}
{'eval_loss': 2.375312566757202, 'eval_f1': 0.33691756272401435, 'eval_precision': 0.33691756272401435, 'eval_recall': 0.33691756272401435, 'eval_runtime': 2.7368, 'eval_samples_per_second': 101.945, 'eval_steps_per_second': 3.289, 'epoch': 0.72}
{'loss': 2.4033, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.08}
{'eval_loss': 2.1277196407318115, 'eval_f1': 0.45878136200716846, 'eval_precision': 0.45878136200716846, 'eval_recall': 0.45878136200716846, 'eval_runtime': 2.7452, 'eval_samples_per_second': 101.631, 'eval_steps_per_second': 3.278, 'epoch': 1.08}
{'loss': 2.1673, 'learning_rate': 7.333333333333333e-06, 'epoch': 1.43}
{'eval_loss': 1.9857934713363647, 'eval_f1': 0.48028673835125446, 'eval_precision': 0.48028673835125446, 'eval_recall': 0.48028673835125446, 'eval_runtime': 2.7534, 'eval_samples_per_second': 101.329, 'eval_steps_per_second': 3.269, 'epoch': 1.43}
{'loss': 2.1495, 'learning_rate': 6.666666666666667e-06, 'epoch': 1.79}
{'eval_loss': 1.8908262252807617, 'eval_f1': 0.48028673835125446, 'eval_precision': 0.48028673835125446, 'eval_recall': 0.48028673835125446, 'eval_runtime': 2.7621, 'eval_samples_per_second': 101.01, 'eval_steps_per_second': 3.258, 'epoch': 1.79}
{'loss': 1.9712, 'learning_rate': 6e-06, 'epoch': 2.15}
{'eval_loss': 1.7763983011245728, 'eval_f1': 0.5448028673835126, 'eval_precision': 0.5448028673835126, 'eval_recall': 0.5448028673835126, 'eval_runtime': 2.751, 'eval_samples_per_second': 101.417, 'eval_steps_per_second': 3.272, 'epoch': 2.15}
{'loss': 1.8053, 'learning_rate': 5.333333333333334e-06, 'epoch': 2.51}
{'eval_loss': 1.7971458435058594, 'eval_f1': 0.5089605734767025, 'eval_precision': 0.5089605734767025, 'eval_recall': 0.5089605734767025, 'eval_runtime': 2.7512, 'eval_samples_per_second': 101.41, 'eval_steps_per_second': 3.271, 'epoch': 2.51}
{'loss': 1.8658, 'learning_rate': 4.666666666666667e-06, 'epoch': 2.87}
{'eval_loss': 1.7818987369537354, 'eval_f1': 0.5089605734767025, 'eval_precision': 0.5089605734767025, 'eval_recall': 0.5089605734767025, 'eval_runtime': 2.753, 'eval_samples_per_second': 101.344, 'eval_steps_per_second': 3.269, 'epoch': 2.87}
{'loss': 1.7725, 'learning_rate': 4.000000000000001e-06, 'epoch': 3.23}
{'eval_loss': 1.669777512550354, 'eval_f1': 0.5483870967741935, 'eval_precision': 0.5483870967741935, 'eval_recall': 0.5483870967741935, 'eval_runtime': 2.755, 'eval_samples_per_second': 101.271, 'eval_steps_per_second': 3.267, 'epoch': 3.23}
{'loss': 1.6255, 'learning_rate': 3.3333333333333333e-06, 'epoch': 3.58}
{'eval_loss': 1.6506106853485107, 'eval_f1': 0.5161290322580645, 'eval_precision': 0.5161290322580645, 'eval_recall': 0.5161290322580645, 'eval_runtime': 2.7534, 'eval_samples_per_second': 101.331, 'eval_steps_per_second': 3.269, 'epoch': 3.58}
{'loss': 1.6842, 'learning_rate': 2.666666666666667e-06, 'epoch': 3.94}
{'eval_loss': 1.6032127141952515, 'eval_f1': 0.5627240143369175, 'eval_precision': 0.5627240143369175, 'eval_recall': 0.5627240143369175, 'eval_runtime': 2.7455, 'eval_samples_per_second': 101.622, 'eval_steps_per_second': 3.278, 'epoch': 3.94}
{'loss': 1.5352, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.3}
{'eval_loss': 1.6392452716827393, 'eval_f1': 0.5125448028673835, 'eval_precision': 0.5125448028673835, 'eval_recall': 0.5125448028673835, 'eval_runtime': 2.7551, 'eval_samples_per_second': 101.265, 'eval_steps_per_second': 3.267, 'epoch': 4.3}
{'loss': 1.5582, 'learning_rate': 1.3333333333333334e-06, 'epoch': 4.66}
{'eval_loss': 1.5939929485321045, 'eval_f1': 0.5376344086021505, 'eval_precision': 0.5376344086021505, 'eval_recall': 0.5376344086021505, 'eval_runtime': 2.7492, 'eval_samples_per_second': 101.483, 'eval_steps_per_second': 3.274, 'epoch': 4.66}
{'loss': 1.5694, 'learning_rate': 6.666666666666667e-07, 'epoch': 5.02}
{'eval_loss': 1.606547236442566, 'eval_f1': 0.5448028673835126, 'eval_precision': 0.5448028673835126, 'eval_recall': 0.5448028673835126, 'eval_runtime': 2.7486, 'eval_samples_per_second': 101.506, 'eval_steps_per_second': 3.274, 'epoch': 5.02}
{'loss': 1.4826, 'learning_rate': 0.0, 'epoch': 5.38}
{'eval_loss': 1.6146608591079712, 'eval_f1': 0.5412186379928315, 'eval_precision': 0.5412186379928315, 'eval_recall': 0.5412186379928315, 'eval_runtime': 2.7512, 'eval_samples_per_second': 101.41, 'eval_steps_per_second': 3.271, 'epoch': 5.38}
{'train_runtime': 462.7358, 'train_samples_per_second': 25.933, 'train_steps_per_second': 3.242, 'train_loss': 1.9485387776692709, 'epoch': 5.38}
F1: 0.4910394265232975
DOWNSAMPLED ENGLISH WITH XLMR BASE(?)
MULTICLASS
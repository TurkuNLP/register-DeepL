8
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 0.2926, 'learning_rate': 6.857142857142856e-06, 'epoch': 1.0}
{'eval_loss': 0.2339135855436325, 'eval_f1': 0.6923512747875354, 'eval_roc_auc': 0.8113708343497535, 'eval_accuracy': 0.5629820051413882, 'eval_runtime': 23.9649, 'eval_samples_per_second': 32.464, 'eval_steps_per_second': 1.043, 'epoch': 1.0}
{'loss': 0.1882, 'learning_rate': 5.7142857142857145e-06, 'epoch': 2.0}
{'eval_loss': 0.21291501820087433, 'eval_f1': 0.7315700619020823, 'eval_roc_auc': 0.8352251615207499, 'eval_accuracy': 0.6131105398457584, 'eval_runtime': 23.8877, 'eval_samples_per_second': 32.569, 'eval_steps_per_second': 1.047, 'epoch': 2.0}
{'loss': 0.1466, 'learning_rate': 4.571428571428571e-06, 'epoch': 3.0}
{'eval_loss': 0.17527568340301514, 'eval_f1': 0.7741935483870968, 'eval_roc_auc': 0.8627162659140525, 'eval_accuracy': 0.6452442159383034, 'eval_runtime': 23.8974, 'eval_samples_per_second': 32.556, 'eval_steps_per_second': 1.046, 'epoch': 3.0}
{'loss': 0.1143, 'learning_rate': 3.428571428571428e-06, 'epoch': 4.0}
{'eval_loss': 0.1926679015159607, 'eval_f1': 0.7683741648106904, 'eval_roc_auc': 0.8590608586100311, 'eval_accuracy': 0.6542416452442159, 'eval_runtime': 23.8741, 'eval_samples_per_second': 32.588, 'eval_steps_per_second': 1.047, 'epoch': 4.0}
{'loss': 0.0917, 'learning_rate': 2.2857142857142856e-06, 'epoch': 5.0}
{'eval_loss': 0.1884346753358841, 'eval_f1': 0.7762008733624455, 'eval_roc_auc': 0.86912357302323, 'eval_accuracy': 0.6619537275064268, 'eval_runtime': 23.8887, 'eval_samples_per_second': 32.568, 'eval_steps_per_second': 1.047, 'epoch': 5.0}
{'loss': 0.0742, 'learning_rate': 1.1428571428571428e-06, 'epoch': 6.0}
{'eval_loss': 0.19171950221061707, 'eval_f1': 0.7826086956521738, 'eval_roc_auc': 0.8705362684460969, 'eval_accuracy': 0.6619537275064268, 'eval_runtime': 23.8988, 'eval_samples_per_second': 32.554, 'eval_steps_per_second': 1.046, 'epoch': 6.0}
{'loss': 0.065, 'learning_rate': 0.0, 'epoch': 7.0}
{'eval_loss': 0.19535981118679047, 'eval_f1': 0.782656421514819, 'eval_roc_auc': 0.8713466255363866, 'eval_accuracy': 0.6683804627249358, 'eval_runtime': 23.8674, 'eval_samples_per_second': 32.597, 'eval_steps_per_second': 1.047, 'epoch': 7.0}
{'train_runtime': 1655.5281, 'train_samples_per_second': 8.173, 'train_steps_per_second': 1.171, 'train_loss': 0.13894507637830542, 'epoch': 7.0}
F1: 0.7739420935412027

SweCore still not good enough with 7 epochs, learning rate 8e-6
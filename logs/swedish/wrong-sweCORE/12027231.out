huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 0.2925, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}
{'eval_loss': 0.2342614084482193, 'eval_f1': 0.6869871043376319, 'eval_roc_auc': 0.800911741789126, 'eval_accuracy': 0.5822622107969152, 'eval_runtime': 24.4321, 'eval_samples_per_second': 31.843, 'eval_steps_per_second': 1.023, 'epoch': 1.0}
{'loss': 0.2196, 'learning_rate': 2.6666666666666667e-05, 'epoch': 2.0}
{'eval_loss': 0.1942155510187149, 'eval_f1': 0.7243553008595988, 'eval_roc_auc': 0.8267076116749885, 'eval_accuracy': 0.6182519280205655, 'eval_runtime': 24.4341, 'eval_samples_per_second': 31.841, 'eval_steps_per_second': 1.023, 'epoch': 2.0}
{'loss': 0.1627, 'learning_rate': 2e-05, 'epoch': 3.0}
{'eval_loss': 0.20086705684661865, 'eval_f1': 0.7479224376731302, 'eval_roc_auc': 0.848603824621969, 'eval_accuracy': 0.6349614395886889, 'eval_runtime': 24.4304, 'eval_samples_per_second': 31.846, 'eval_steps_per_second': 1.023, 'epoch': 3.0}
{'loss': 0.1203, 'learning_rate': 1.3333333333333333e-05, 'epoch': 4.0}
{'eval_loss': 0.18944668769836426, 'eval_f1': 0.768107804604155, 'eval_roc_auc': 0.8566297873391612, 'eval_accuracy': 0.6529562982005142, 'eval_runtime': 24.4492, 'eval_samples_per_second': 31.821, 'eval_steps_per_second': 1.023, 'epoch': 4.0}
{'loss': 0.0875, 'learning_rate': 6.666666666666667e-06, 'epoch': 5.0}
{'eval_loss': 0.19275318086147308, 'eval_f1': 0.7751351351351351, 'eval_roc_auc': 0.8712721052095267, 'eval_accuracy': 0.6670951156812339, 'eval_runtime': 24.4237, 'eval_samples_per_second': 31.854, 'eval_steps_per_second': 1.024, 'epoch': 5.0}
{'loss': 0.0611, 'learning_rate': 0.0, 'epoch': 6.0}
{'eval_loss': 0.1979341059923172, 'eval_f1': 0.7883683360258482, 'eval_roc_auc': 0.8802222640798645, 'eval_accuracy': 0.6773778920308483, 'eval_runtime': 24.4143, 'eval_samples_per_second': 31.867, 'eval_steps_per_second': 1.024, 'epoch': 6.0}
{'train_runtime': 1472.2973, 'train_samples_per_second': 7.877, 'train_steps_per_second': 1.129, 'train_loss': 0.1572987341852108, 'epoch': 6.0}
F1: 0.7678471051152334

SWE
--batch 7 --treshold 0.4 --epochs 6 --learning 4e-5

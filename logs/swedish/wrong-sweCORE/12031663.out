Downloading and preparing dataset csv/default to /users/annieske/.cache/huggingface/datasets/csv/default-c3a76f4580d57d93/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...
Dataset csv downloaded and prepared to /users/annieske/.cache/huggingface/datasets/csv/default-c3a76f4580d57d93/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.
['IN', None, 'NA OP', 'ID', 'NA OP']
[['IN'], ['NA'], ['NA', 'OP'], ['ID'], ['NA', 'OP']]
[[0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0],
 [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0]]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 0.2802, 'learning_rate': 8.333333333333334e-06, 'epoch': 1.0}
{'eval_loss': 0.2145053744316101, 'eval_f1': 0.7050691244239632, 'eval_roc_auc': 0.811068342545804, 'eval_accuracy': 0.5964316057774002, 'eval_runtime': 38.0973, 'eval_samples_per_second': 30.895, 'eval_steps_per_second': 0.971, 'epoch': 1.0}
{'loss': 0.1753, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}
{'eval_loss': 0.18638287484645844, 'eval_f1': 0.7613636363636364, 'eval_roc_auc': 0.8454522659529908, 'eval_accuracy': 0.6550552251486831, 'eval_runtime': 39.5648, 'eval_samples_per_second': 29.749, 'eval_steps_per_second': 0.935, 'epoch': 2.0}
{'loss': 0.1337, 'learning_rate': 5e-06, 'epoch': 3.0}
{'eval_loss': 0.17575781047344208, 'eval_f1': 0.7854518736223366, 'eval_roc_auc': 0.8672858748913944, 'eval_accuracy': 0.6796941376380629, 'eval_runtime': 37.2949, 'eval_samples_per_second': 31.559, 'eval_steps_per_second': 0.992, 'epoch': 3.0}
{'loss': 0.1033, 'learning_rate': 3.3333333333333333e-06, 'epoch': 4.0}
{'eval_loss': 0.17116466164588928, 'eval_f1': 0.7972130546387971, 'eval_roc_auc': 0.8745523876770731, 'eval_accuracy': 0.6847918436703483, 'eval_runtime': 37.4206, 'eval_samples_per_second': 31.453, 'eval_steps_per_second': 0.989, 'epoch': 4.0}
{'loss': 0.0794, 'learning_rate': 1.6666666666666667e-06, 'epoch': 5.0}
{'eval_loss': 0.17351467907428741, 'eval_f1': 0.8004402054292002, 'eval_roc_auc': 0.8762987508884285, 'eval_accuracy': 0.6907391673746814, 'eval_runtime': 38.1937, 'eval_samples_per_second': 30.817, 'eval_steps_per_second': 0.969, 'epoch': 5.0}
{'loss': 0.0637, 'learning_rate': 0.0, 'epoch': 6.0}
{'eval_loss': 0.17734059691429138, 'eval_f1': 0.8017429193899782, 'eval_roc_auc': 0.8800266626890828, 'eval_accuracy': 0.6941376380628717, 'eval_runtime': 37.3962, 'eval_samples_per_second': 31.474, 'eval_steps_per_second': 0.989, 'epoch': 6.0}
{'train_runtime': 1607.4293, 'train_samples_per_second': 7.215, 'train_steps_per_second': 1.034, 'train_loss': 0.13926987584891015, 'epoch': 6.0}
F1: 0.7904391328515841

SWE
test with --batch 7 --treshold 0.4 --epochs 6 --learning 1e-5
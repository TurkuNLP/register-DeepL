huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 0.3666, 'learning_rate': 2.5e-06, 'epoch': 1.0}
{'eval_loss': 0.3033409118652344, 'eval_f1': 0.4609773887673232, 'eval_roc_auc': 0.6594924383483249, 'eval_accuracy': 0.3110539845758355, 'eval_runtime': 23.9614, 'eval_samples_per_second': 32.469, 'eval_steps_per_second': 1.043, 'epoch': 1.0}
{'loss': 0.2473, 'learning_rate': 2e-06, 'epoch': 2.0}
{'eval_loss': 0.2368277758359909, 'eval_f1': 0.6650485436893203, 'eval_roc_auc': 0.7820303083638773, 'eval_accuracy': 0.5668380462724936, 'eval_runtime': 23.9326, 'eval_samples_per_second': 32.508, 'eval_steps_per_second': 1.045, 'epoch': 2.0}
{'loss': 0.2016, 'learning_rate': 1.5e-06, 'epoch': 3.0}
{'eval_loss': 0.2020293027162552, 'eval_f1': 0.7356051703877792, 'eval_roc_auc': 0.8269135718601365, 'eval_accuracy': 0.609254498714653, 'eval_runtime': 23.9228, 'eval_samples_per_second': 32.521, 'eval_steps_per_second': 1.045, 'epoch': 3.0}
{'loss': 0.1767, 'learning_rate': 1e-06, 'epoch': 4.0}
{'eval_loss': 0.19248679280281067, 'eval_f1': 0.7530791788856305, 'eval_roc_auc': 0.8368810772921949, 'eval_accuracy': 0.6323907455012854, 'eval_runtime': 23.9299, 'eval_samples_per_second': 32.512, 'eval_steps_per_second': 1.045, 'epoch': 4.0}
{'loss': 0.1635, 'learning_rate': 5e-07, 'epoch': 5.0}
{'eval_loss': 0.18722479045391083, 'eval_f1': 0.7495621716287216, 'eval_roc_auc': 0.8361276397333326, 'eval_accuracy': 0.6323907455012854, 'eval_runtime': 23.9074, 'eval_samples_per_second': 32.542, 'eval_steps_per_second': 1.046, 'epoch': 5.0}
{'loss': 0.154, 'learning_rate': 0.0, 'epoch': 6.0}
{'eval_loss': 0.1886267364025116, 'eval_f1': 0.7498542274052479, 'eval_roc_auc': 0.8365799081259063, 'eval_accuracy': 0.6336760925449871, 'eval_runtime': 23.9158, 'eval_samples_per_second': 32.531, 'eval_steps_per_second': 1.045, 'epoch': 6.0}
{'train_runtime': 1498.0291, 'train_samples_per_second': 7.742, 'train_steps_per_second': 0.969, 'train_loss': 0.2182863408868963, 'epoch': 6.0}
F1: 0.7492694330800701


SWE
--batch 8 --treshold 0.4 --epochs 6 --learning 3e-6
Downloading and preparing dataset csv/default to /users/annieske/.cache/huggingface/datasets/csv/default-1cdeb115d3a0a367/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...
Dataset csv downloaded and prepared to /users/annieske/.cache/huggingface/datasets/csv/default-1cdeb115d3a0a367/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.
['IP', 'IN', 'IN', 'IN', None]
[['IP'], ['IN'], ['IN'], ['IN'], ['NA']]
[[0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0],
 [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0]]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 0.3127, 'learning_rate': 8.333333333333334e-06, 'epoch': 1.0}
{'eval_loss': 0.22084611654281616, 'eval_f1': 0.7253446447507953, 'eval_roc_auc': 0.8287776443017782, 'eval_accuracy': 0.6436781609195402, 'eval_runtime': 13.126, 'eval_samples_per_second': 33.14, 'eval_steps_per_second': 1.067, 'epoch': 1.0}
{'loss': 0.1907, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}
{'eval_loss': 0.1784089058637619, 'eval_f1': 0.7709251101321586, 'eval_roc_auc': 0.8440890919474585, 'eval_accuracy': 0.6804597701149425, 'eval_runtime': 13.1125, 'eval_samples_per_second': 33.175, 'eval_steps_per_second': 1.068, 'epoch': 2.0}
{'loss': 0.1423, 'learning_rate': 5e-06, 'epoch': 3.0}
{'eval_loss': 0.1589413285255432, 'eval_f1': 0.8066528066528067, 'eval_roc_auc': 0.8799503731857659, 'eval_accuracy': 0.728735632183908, 'eval_runtime': 13.097, 'eval_samples_per_second': 33.214, 'eval_steps_per_second': 1.069, 'epoch': 3.0}
{'loss': 0.1127, 'learning_rate': 3.3333333333333333e-06, 'epoch': 4.0}
{'eval_loss': 0.15011020004749298, 'eval_f1': 0.8252326783867632, 'eval_roc_auc': 0.8921109119911775, 'eval_accuracy': 0.7471264367816092, 'eval_runtime': 13.1055, 'eval_samples_per_second': 33.192, 'eval_steps_per_second': 1.068, 'epoch': 4.0}
{'loss': 0.0894, 'learning_rate': 1.6666666666666667e-06, 'epoch': 5.0}
{'eval_loss': 0.15183083713054657, 'eval_f1': 0.8258602711157456, 'eval_roc_auc': 0.8899052758029894, 'eval_accuracy': 0.7494252873563219, 'eval_runtime': 13.1095, 'eval_samples_per_second': 33.182, 'eval_steps_per_second': 1.068, 'epoch': 5.0}
{'loss': 0.0757, 'learning_rate': 0.0, 'epoch': 6.0}
{'eval_loss': 0.15115417540073395, 'eval_f1': 0.820618556701031, 'eval_roc_auc': 0.8904271450796589, 'eval_accuracy': 0.7379310344827587, 'eval_runtime': 13.1043, 'eval_samples_per_second': 33.195, 'eval_steps_per_second': 1.068, 'epoch': 6.0}
{'train_runtime': 843.1002, 'train_samples_per_second': 7.778, 'train_steps_per_second': 1.117, 'train_loss': 0.15392111213343918, 'epoch': 6.0}
F1: 0.8307905686546464

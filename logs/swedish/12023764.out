huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 0.3605, 'learning_rate': 2.5e-06, 'epoch': 1.0}
{'eval_loss': 0.2658771574497223, 'eval_f1': 0.6351875808538162, 'eval_roc_auc': 0.7551208536488713, 'eval_accuracy': 0.5167095115681234, 'eval_runtime': 23.8039, 'eval_samples_per_second': 32.684, 'eval_steps_per_second': 1.05, 'epoch': 1.0}
{'loss': 0.2289, 'learning_rate': 2e-06, 'epoch': 2.0}
{'eval_loss': 0.22681032121181488, 'eval_f1': 0.6823671497584541, 'eval_roc_auc': 0.7921675431039363, 'eval_accuracy': 0.5809768637532133, 'eval_runtime': 23.5856, 'eval_samples_per_second': 32.986, 'eval_steps_per_second': 1.06, 'epoch': 2.0}
{'loss': 0.1905, 'learning_rate': 1.5e-06, 'epoch': 3.0}
{'eval_loss': 0.19966286420822144, 'eval_f1': 0.7369668246445498, 'eval_roc_auc': 0.8256695764589876, 'eval_accuracy': 0.62853470437018, 'eval_runtime': 23.5976, 'eval_samples_per_second': 32.97, 'eval_steps_per_second': 1.059, 'epoch': 3.0}
{'loss': 0.167, 'learning_rate': 1e-06, 'epoch': 4.0}
{'eval_loss': 0.19342882931232452, 'eval_f1': 0.7393087287639133, 'eval_roc_auc': 0.829645812297295, 'eval_accuracy': 0.615681233933162, 'eval_runtime': 23.5761, 'eval_samples_per_second': 33.0, 'eval_steps_per_second': 1.06, 'epoch': 4.0}
{'loss': 0.1531, 'learning_rate': 5e-07, 'epoch': 5.0}
{'eval_loss': 0.18934474885463715, 'eval_f1': 0.7433217189314751, 'eval_roc_auc': 0.8339987669150334, 'eval_accuracy': 0.6208226221079691, 'eval_runtime': 23.5893, 'eval_samples_per_second': 32.981, 'eval_steps_per_second': 1.06, 'epoch': 5.0}
{'loss': 0.1436, 'learning_rate': 0.0, 'epoch': 6.0}
{'eval_loss': 0.19100865721702576, 'eval_f1': 0.7421602787456445, 'eval_roc_auc': 0.8333581391327438, 'eval_accuracy': 0.6208226221079691, 'eval_runtime': 23.5444, 'eval_samples_per_second': 33.044, 'eval_steps_per_second': 1.062, 'epoch': 6.0}
{'train_runtime': 1402.2979, 'train_samples_per_second': 8.271, 'train_steps_per_second': 1.185, 'train_loss': 0.20728649961102022, 'epoch': 6.0}
F1: 0.7430232558139535

SWE 
--batch 7 --treshold 0.4 --epochs 6 --learning 3e-6